{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Analytics with ArangoDB (Python-Arango Library) (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-arango in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-arango) (2.2.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-arango) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-arango) (1.0.0)\n",
      "Requirement already satisfied: PyJWT in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-arango) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=42 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-arango) (65.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-arango) (8.5.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/briandunn/Library/Python/3.11/lib/python/site-packages (from python-arango) (24.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from importlib-metadata>=4.7.1->python-arango) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->python-arango) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->python-arango) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->python-arango) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scipy) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: geopandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from geopandas) (2.1.3)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in /Users/briandunn/Library/Python/3.11/lib/python/site-packages (from geopandas) (24.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from geopandas) (2.2.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from geopandas) (3.7.0)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from geopandas) (2.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/briandunn/Library/Python/3.11/lib/python/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /Users/briandunn/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-arango\n",
    "%pip install networkx\n",
    "%pip install numpy\n",
    "%pip install scipy\n",
    "%pip install tabulate\n",
    "%pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, csv, statistics\n",
    "\n",
    "from arango import ArangoClient\n",
    "import networkx as nx\n",
    "import pkg_resources\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tabulate import tabulate\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Software & Library Versions \n",
      "----------------|------------\n",
      "         Python | 3.11.4\n",
      "  Arango Client | 8.1.2\n",
      "       NetworkX | 3.4.2\n",
      "          NumPy | 2.1.3\n",
      "          SciPy | 1.14.1\n"
     ]
    }
   ],
   "source": [
    "l = 15\n",
    "r = 14\n",
    "\n",
    "arango_version = pkg_resources.get_distribution(\"python-arango\").version\n",
    "\n",
    "print(\"Software & Library Versions\".center(l+r))\n",
    "print('-'* (l + 1) + '|' + '-' * (r - 2))\n",
    "print('Python'.rjust(l), '|', sys.version[0:6])\n",
    "print('Arango Client'.rjust(l), '|', arango_version)\n",
    "print('NetworkX'.rjust(l), '|', nx.__version__)\n",
    "print('NumPy'.rjust(l), '|', np.__version__)\n",
    "print('SciPy'.rjust(l), '|', scipy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ArangoDB\n",
    "client = ArangoClient()\n",
    "db = client.db('_system', username='root', password='testpassword')\n",
    "\n",
    "# Access collections\n",
    "nodes = db.collection('airports')\n",
    "edges = db.collection('flights')\n",
    "\n",
    "# Fetch graph data\n",
    "graph_data = {\n",
    "    'nodes': list(nodes.all()),\n",
    "    'edges': list(edges.all())\n",
    "}\n",
    "\n",
    "flightGraph = nx.MultiDiGraph()\n",
    "\n",
    "# Add nodes\n",
    "for node in graph_data['nodes']:\n",
    "    flightGraph.add_node(node['_key'], **node)\n",
    "\n",
    "# Add edges\n",
    "for edge in graph_data['edges']:\n",
    "    flightGraph.add_edge(\n",
    "        edge['_from'].split('/')[-1],\n",
    "        edge['_to'].split('/')[-1],\n",
    "        **edge\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Introductory Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Number Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'NumberOfAirports': 365}]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "FOR airport IN airports\n",
    "    COLLECT WITH COUNT INTO numAirports\n",
    "RETURN { NumberOfAirports: numAirports }\n",
    "\"\"\"\n",
    "result = db.aql.execute(query)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the Number of Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'NumberOfFlights': 992298}]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "FOR flight IN flights\n",
    "    COLLECT WITH COUNT INTO numFlights\n",
    "RETURN { NumberOfFlights: numFlights }\n",
    "\"\"\"\n",
    "result = db.aql.execute(query)\n",
    "\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Airline Names for Each Airline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "with open('../import/airlines.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        query = \"\"\"\n",
    "        FOR flight IN flights\n",
    "            FILTER flight.airline_id == @airline_id\n",
    "            UPDATE flight WITH {\n",
    "                airline_name: @airline_name,\n",
    "                airline_code: @airline_code\n",
    "            } IN flights\n",
    "        \"\"\"\n",
    "        db.aql.execute(query, bind_vars={\n",
    "            'airline_id': row['airline_id'],\n",
    "            'airline_name': row['airline_name'],\n",
    "            'airline_code': row['airline_code']\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Airport Name, City, & State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../import/airports.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        query = \"\"\"\n",
    "        FOR airport IN airports\n",
    "            FILTER airport.unique_id == @unique_id\n",
    "            UPDATE airport WITH {\n",
    "                airport_code: @airport_code,\n",
    "                airport_name: @airport_name,\n",
    "                airport_city: @city_name,\n",
    "                airportState_code: @state,\n",
    "                airportState_name: @state_name\n",
    "            } IN airports\n",
    "        \"\"\"\n",
    "        db.aql.execute(query, bind_vars={\n",
    "            'unique_id': row['unique_id'],\n",
    "            'airport_code': row['airport_code'],\n",
    "            'airport_name': row['airport_name'],\n",
    "            'city_name': row['city_name'],\n",
    "            'state': row['state'],\n",
    "            'state_name': row['state_name']\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Node ID Based On Value of Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_by_attribute(graph, attribute_name, attribute_value):\n",
    "    \"\"\"\n",
    "    Find the node in the graph that matches the given attribute value.\n",
    "    \n",
    "    Args:\n",
    "        graph (nx.Graph): The NetworkX graph.\n",
    "        attribute_name (str): The name of the attribute to search by.\n",
    "        attribute_value (str): The value of the attribute to match.\n",
    "        \n",
    "    Returns:\n",
    "        The ID of the node that matches the given attribute value, or None if not found.\n",
    "    \"\"\"\n",
    "    for node, attributes in graph.nodes(data=True):\n",
    "        if attributes.get(attribute_name) == attribute_value:\n",
    "            return node  # Return node ID\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Value of Attribute Based On Node ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_node_id_to_attr_value(data, mapping_dict, attribute_name):\n",
    "    \"\"\"\n",
    "    Replace keys in a list of tuples with the corresponding attribute values from a mapping dictionary.\n",
    "    \n",
    "    Args:\n",
    "        data (list of tuples): The input list containing (key, value) pairs.\n",
    "        mapping_dict (dict): A dictionary where keys are node/airport IDs and values are dictionaries of attributes.\n",
    "        attribute_name (str): The name of the attribute to replace the key with.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples where the keys are replaced with the specified attribute values.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, list) or not all(isinstance(item, tuple) and len(item) == 2 for item in data):\n",
    "        raise ValueError(\"Data must be a list of (key, value) tuples.\")\n",
    "    \n",
    "    if not isinstance(mapping_dict, dict):\n",
    "        raise ValueError(\"Mapping dictionary must be a valid dictionary.\")\n",
    "    \n",
    "    if not isinstance(attribute_name, str):\n",
    "        raise ValueError(\"Attribute name must be a string.\")\n",
    "    \n",
    "    # Replace keys with the specified attribute value\n",
    "    updated_data = []\n",
    "    for key, value in data:\n",
    "        attribute_value = mapping_dict.get(key, {}).get(attribute_name, key)  # Default to the original key if attribute is missing\n",
    "        updated_data.append((attribute_value, value))\n",
    "    \n",
    "    return updated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Create Maps Between Ids & Attribute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'179': 'FWA', '181': 'BZN', '183': 'RDM', '185': 'BKG', '187': 'MQT', '189': 'JAC', '191': 'MSP', '193': 'HIB', '195': 'UCA', '197': 'AUS', '199': 'HDN', '201': 'MAZ', '203': 'ANI', '205': 'CDC', '207': 'AMA', '209': 'PSC', '211': 'PVD', '213': 'AGS', '215': 'AVL', '217': 'CVG', '219': 'PLN', '221': 'PBI', '223': 'LMT', '225': 'BTM', '227': 'CPR', '229': 'ITH', '231': 'UTM', '233': 'CRW', '235': 'YUM', '237': 'DHN', '239': 'ATL', '241': 'MKG', '243': 'JAN', '245': 'LCH', '247': 'DIK', '249': 'LNY', '251': 'EWN', '253': 'ROW', '255': 'ITO', '257': 'ELM', '259': 'MWH', '261': 'HOB', '263': 'MCO', '265': 'EGE', '267': 'SLC', '269': 'CHO', '271': 'ECP', '273': 'ORD', '275': 'ISN', '277': 'SAN', '279': 'PDX', '281': 'GSO', '283': 'PIH', '285': 'MCN', '287': 'BNA', '289': 'SEA', '291': 'SAT', '293': 'SMX', '295': 'FSD', '297': 'BRD', '299': 'HOU', '301': 'EKO', '303': 'ERI', '305': 'GRR', '307': 'BFL', '309': 'SPN', '311': 'TUL', '313': 'INL', '315': 'DUT', '317': 'ATW', '319': 'HRL', '321': 'BOI', '323': 'ACK', '325': 'GJT', '327': 'LNK', '329': 'PBG', '331': 'RDU', '333': 'DRO', '335': 'SAF', '337': 'RAP', '339': 'GEG', '341': 'FOE', '343': 'AEX', '345': 'HYA', '347': 'VPS', '349': 'BOS', '351': 'EWR', '353': 'JNU', '355': 'RFD', '357': 'TYR', '359': 'ABR', '361': 'SBP', '363': 'MOT', '365': 'TUS', '367': 'OGG', '369': 'JMS', '371': 'UST', '373': 'XNA', '375': 'CLD', '377': 'SYR', '379': 'CAK', '381': 'VCT', '383': 'PFN', '385': 'PSP', '387': 'MDW', '389': 'IAH', '391': 'PIA', '393': 'ACY', '395': 'CEC', '397': 'HYS', '399': 'STL', '401': 'GST', '403': 'ONT', '405': 'OKC', '407': 'SGF', '409': 'PHL', '411': 'MIA', '413': 'LBB', '415': 'FNT', '417': 'HLN', '419': 'LFT', '421': 'TWF', '423': 'FAR', '425': 'BIL', '427': 'MSY', '429': 'GUC', '431': 'EFD', '433': 'BIS', '435': 'SBN', '437': 'STX', '439': 'COU', '441': 'MIB', '443': 'IDA', '445': 'HTS', '447': 'BJI', '449': 'DCA', '451': 'EYW', '453': 'SMF', '455': 'SGU', '457': 'RKS', '459': 'SUN', '461': 'MSN', '463': 'MFR', '465': 'ALO', '467': 'DVL', '469': 'FLG', '471': 'FLL', '473': 'FCA', '475': 'CAE', '477': 'SCE', '479': 'ABE', '481': 'BGM', '483': 'WYS', '485': 'RSW', '487': 'HNL', '489': 'AZA', '491': 'MEI', '493': 'LAX', '495': 'MVY', '497': 'DRT', '499': 'TEX', '501': 'LRD', '503': 'BRO', '505': 'PHF', '507': 'STT', '509': 'MKE', '511': 'HPN', '513': 'ILE', '515': 'BHM', '517': 'MBS', '519': 'HVN', '521': 'DSM', '523': 'TVC', '525': 'CIU', '527': 'LGB', '529': 'BWI', '531': 'CYS', '533': 'SJC', '535': 'DAY', '537': 'MYR', '539': 'LGA', '541': 'CMX', '543': 'ILG', '545': 'ESC', '547': 'BUR', '549': 'LAW', '551': 'VEL', '553': 'RIC', '555': 'ISO', '557': 'MTJ', '559': 'SHV', '561': 'SIT', '563': 'GCK', '565': 'PNS', '567': 'BQN', '569': 'FAT', '571': 'APF', '573': 'KSM', '575': 'DTW', '577': 'FAY', '579': 'MLB', '581': 'PAH', '583': 'BTR', '585': 'MHT', '587': 'MLI', '589': 'TYS', '591': 'CMI', '593': 'YAK', '595': 'WRG', '597': 'PUB', '599': 'GPT', '601': 'LWB', '603': 'JLN', '605': 'GSP', '607': 'ART', '609': 'PSG', '611': 'SHD', '613': 'SWF', '615': 'TLH', '617': 'SPS', '619': 'OTZ', '621': 'FLO', '623': 'MSO', '625': 'GCC', '627': 'IAG', '629': 'LBE', '631': 'CNY', '633': 'EVV', '635': 'GGG', '637': 'PPG', '639': 'OXR', '641': 'IPL', '643': 'GTF', '645': 'TOL', '647': 'ANC', '649': 'CMH', '651': 'ABQ', '653': 'BRW', '655': 'LIH', '657': 'ROP', '659': 'IMT', '661': 'RDD', '663': 'CLT', '665': 'SNA', '667': 'MAF', '669': 'ASE', '671': 'LAS', '673': 'CWA', '675': 'OME', '677': 'SUX', '679': 'TXK', '681': 'CRP', '683': 'ROR', '685': 'CLL', '687': 'LWS', '689': 'PIE', '691': 'MFE', '693': 'AZO', '695': 'GUM', '697': 'SJU', '699': 'BUF', '701': 'LIT', '703': 'ROA', '705': 'MHK', '707': 'BTV', '709': 'VLD', '711': 'GTR', '713': 'ROC', '715': 'PHX', '717': 'SJT', '719': 'MGM', '721': 'APN', '723': 'IYK', '725': 'CIC', '727': 'EAU', '729': 'PSE', '731': 'TRI', '733': 'DFW', '735': 'COD', '737': 'PIT', '739': 'PIB', '741': 'GFK', '743': 'BQK', '745': 'LAN', '747': 'CID', '749': 'BMI', '751': 'KOA', '753': 'DAL', '755': 'OTH', '757': 'RHI', '759': 'OAK', '761': 'BDL', '763': 'SFO', '765': 'ILM', '767': 'ADK', '769': 'BET', '771': 'HSV', '773': 'DBQ', '775': 'JAX', '777': 'IAD', '779': 'BGR', '781': 'ABI', '783': 'RST', '785': 'ELP', '787': 'OMA', '789': 'MRY', '791': 'GRI', '793': 'LAR', '795': 'TPA', '797': 'GRB', '799': 'DEN', '801': 'LSE', '803': 'KTN', '805': 'MKK', '807': 'CHS', '809': 'ISP', '811': 'CLE', '813': 'ICT', '815': 'GRK', '817': 'ORH', '819': 'EUG', '821': 'CHA', '823': 'MEM', '825': 'VIS', '827': 'RNO', '829': 'IND', '831': 'BPT', '833': 'SBA', '835': 'CDV', '837': 'CSG', '839': 'AKN', '841': 'DAB', '843': 'ACT', '845': 'ALB', '847': 'MCI', '849': 'PWM', '851': 'STC', '853': 'ORF', '855': 'SRQ', '857': 'FAI', '859': 'SPI', '861': 'COS', '863': 'ABY', '865': 'SDF', '867': 'MMH', '869': 'TTN', '871': 'MDT', '873': 'MOB', '875': 'JFK', '877': 'SAV', '879': 'DET', '881': 'GNV', '883': 'ACV', '885': 'LYH', '887': 'MOD', '889': 'DLG', '891': 'ADQ', '893': 'MLU', '895': 'SCC', '897': 'OAJ', '899': 'BLI', '901': 'FSM', '903': 'AVP', '905': 'LEX', '907': 'DLH'}\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "# Function to create a map of node_id's as the keys and as the values\n",
    "\n",
    "def create_airport_code_dict(G):\n",
    "    \"\"\"\n",
    "    Extracts a dictionary mapping node IDs to their respective airport_code attributes from a NetworkX graph.\n",
    "    \n",
    "    Args:\n",
    "        G (networkx.Graph): A NetworkX graph with nodes containing an 'airport_code' attribute.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with node IDs as keys and airport_code as values.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary\n",
    "    airport_code_dict = {}\n",
    "\n",
    "    # Iterate over the nodes and their attributes\n",
    "    for node, attributes in G.nodes(data=True):\n",
    "        airport_code = attributes.get('airport_code')  # Get the airport_code attribute\n",
    "        if airport_code:  # Only include if the airport_code attribute exists\n",
    "            airport_code_dict[node] = airport_code  # Map node ID to airport_code\n",
    "\n",
    "    return airport_code_dict\n",
    "\n",
    "### --------------------------------------------------------------------\n",
    "# Example output:\n",
    "\n",
    "# {\n",
    "#     1: \"JFK\",\n",
    "#     2: \"LAX\"\n",
    "# }\n",
    "### --------------------------------------------------------------------\n",
    "\n",
    "id_to_airport_code_mapping_dict = create_airport_code_dict(flightGraph)\n",
    "\n",
    "print(id_to_airport_code_mapping_dict)\n",
    "print(len(id_to_airport_code_mapping_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dictionary Keys From Node Id's to Airport Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each & every KEY from node_id to the airport_code value\n",
    "\n",
    "def convert_output_keys_to_airport_codes(\n",
    "    nx_output_dict, \n",
    "    node_to_airport_code_dict=id_to_airport_code_mapping_dict):\n",
    "    \"\"\"\n",
    "    Converts the keys of a NetworkX output dictionary from node IDs to airport codes.\n",
    "    \n",
    "    Args:\n",
    "        nx_output_dict (dict): A dictionary output from NetworkX with node IDs as keys.\n",
    "        node_to_airport_code_dict (dict): A dictionary mapping node IDs to airport codes.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with airport codes as keys and the original values preserved.\n",
    "    \"\"\"\n",
    "    converted_dict = {}\n",
    "    \n",
    "    for node_id, value in nx_output_dict.items():\n",
    "        # Get the airport code for the given node ID\n",
    "        airport_code = node_to_airport_code_dict.get(node_id, f\"UNKNOWN({node_id})\")\n",
    "        \n",
    "        # Add to the new dictionary\n",
    "        converted_dict[airport_code] = value\n",
    "\n",
    "    return converted_dict\n",
    "\n",
    "# Example Use:\n",
    "    \n",
    "# converted_dict = convert_output_keys_to_airport_codes(nx_output_dict, id_to_airport_code_mapping_dict)\n",
    "\n",
    "# Example Output:\n",
    "\n",
    "# {\n",
    "#     \"JFK\": 3,\n",
    "#     \"LAX\": 5,\n",
    "#     \"ORD\": 2\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle instances of the value being inputted as a single instance\n",
    "\n",
    "def convert_single_instance(node_id, node_to_airport_code_dict):\n",
    "    \"\"\"\n",
    "    Convert a single node_id (integer) to its corresponding airport_code.\n",
    "    \"\"\"\n",
    "    return node_to_airport_code_dict.get(node_id, node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle instances of the value being inputted as a list \n",
    "\n",
    "def convert_list(node_id_list, node_to_airport_code_dict):\n",
    "    \"\"\"\n",
    "    Convert a list of node_ids (including nested lists) to their corresponding airport_codes.\n",
    "    \"\"\"\n",
    "    converted_list = []\n",
    "    for item in node_id_list:\n",
    "        if isinstance(item, list):\n",
    "            # Recursively process nested lists\n",
    "            converted_list.append(convert_list(item, node_to_airport_code_dict))\n",
    "        else:\n",
    "            # Convert single elements\n",
    "            converted_list.append(node_to_airport_code_dict.get(item, item))\n",
    "    return converted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle instances of the value being inputted as a tuple \n",
    "\n",
    "def convert_tuple(node_id_tuple, node_to_airport_code_dict):\n",
    "    \"\"\"\n",
    "    Convert a tuple of node_ids to their corresponding airport_codes.\n",
    "    \"\"\"\n",
    "    return tuple(node_to_airport_code_dict.get(node_id, node_id) for node_id in node_id_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle instances of the value being inputted as a set\n",
    "\n",
    "def convert_set(node_id_set, node_to_airport_code_dict):\n",
    "    \"\"\"\n",
    "    Convert a set of node_ids to their corresponding airport_codes.\n",
    "    \"\"\"\n",
    "    return {node_to_airport_code_dict.get(node_id, node_id) for node_id in node_id_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle instances of the value being inputted as a dictionary\n",
    "\n",
    "def convert_dict(node_id_dict, node_to_airport_code_dict):\n",
    "    \"\"\"\n",
    "    Convert a dictionary with node_ids in values to their corresponding airport_codes.\n",
    "    \"\"\"\n",
    "    return {key: convert_values(value, node_to_airport_code_dict) for key, value in node_id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_values(value, node_to_airport_code_dict):\n",
    "    \"\"\"\n",
    "    Dynamically determine the type of input value and convert it appropriately.\n",
    "    \"\"\"\n",
    "    if isinstance(value, int):\n",
    "        return convert_single_instance(value, node_to_airport_code_dict)\n",
    "    elif isinstance(value, list):\n",
    "        return convert_list(value, node_to_airport_code_dict)\n",
    "    elif isinstance(value, tuple):\n",
    "        return convert_tuple(value, node_to_airport_code_dict)\n",
    "    elif isinstance(value, set):\n",
    "        return convert_set(value, node_to_airport_code_dict)\n",
    "    elif isinstance(value, dict):\n",
    "        return convert_dict(value, node_to_airport_code_dict)\n",
    "    else:\n",
    "        # If the value doesn't match any known type, return it as is\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert List of Sets of Node Id's to Airport Code's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_node_ids_to_airport_codes(components_list, id_to_airport_code_mapping_dict):\n",
    "    \"\"\"\n",
    "    Converts node IDs to airport codes using a mapping dictionary.\n",
    "\n",
    "    Args:\n",
    "        components_list (list): A list of sets containing node IDs.\n",
    "        id_to_airport_code_mapping_dict (dict): Dictionary mapping node IDs to airport codes.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of sets with node IDs replaced by airport codes.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {id_to_airport_code_mapping_dict.get(node_id, node_id) for node_id in component}\n",
    "        for component in components_list\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function(s) To Modify Output Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Function to Return Statisics About Path Lengths (Dictionary Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_path_stats(path_lengths):\n",
    "    \"\"\"\n",
    "    Analyze the values in a dictionary of path lengths.\n",
    "\n",
    "    Parameters:\n",
    "        path_lengths (dict): A dictionary where keys are nodes and values are path lengths.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with max, mean, and count of the path lengths.\n",
    "    \"\"\"\n",
    "    if not path_lengths:\n",
    "        return {\n",
    "            \"min\": None,\n",
    "            \"max\": None, \n",
    "            \"mean\": None, \n",
    "            \"count\": 0,\n",
    "            \"std Dev\": None,\n",
    "            \"harm_mean\": None,\n",
    "            \"geo_mean\": None,\n",
    "            \"quants\": None,\n",
    "            \"mode\": None\n",
    "        }\n",
    "\n",
    "    # Filter out non-numeric values from the list (e.g., lists, strings, etc.)\n",
    "    values = [v for v in path_lengths.values() if isinstance(v, (int, float))]\n",
    "\n",
    "    if not values:  # Handle case where no valid numeric values exist\n",
    "        return {\n",
    "            \"min\": None,\n",
    "            \"max\": None, \n",
    "            \"mean\": None, \n",
    "            \"count\": 0,\n",
    "            \"std Dev\": None,\n",
    "            \"harmonic_mean\": None,\n",
    "            \"geometric_mean\": None,\n",
    "            \"quants\": None,\n",
    "            \"mode\": None\n",
    "        }\n",
    "\n",
    "    # Ensure all values are positive for geometric mean calculation\n",
    "    positive_values = [v for v in values if v > 0]\n",
    "\n",
    "    min_value = min(values)\n",
    "    max_value = max(values)\n",
    "    mean_value = statistics.mean(values)\n",
    "    count = len(values)\n",
    "    pop_st_dev = statistics.pstdev(values)  # This is the population standard deviation\n",
    "    harm_mean = statistics.harmonic_mean(values)\n",
    "\n",
    "    # Calculate the geometric mean if there are positive values\n",
    "    if positive_values:\n",
    "        geo_mean = statistics.geometric_mean(positive_values)\n",
    "    else:\n",
    "        geo_mean = None  # No valid positive values for geometric mean\n",
    "\n",
    "    quants = statistics.quantiles(values, n=5)\n",
    "\n",
    "    try:\n",
    "        modes = statistics.mode(values)\n",
    "    except statistics.StatisticsError:\n",
    "        modes = None  # In case there are no unique modes\n",
    "\n",
    "    return {\n",
    "        \"min\": min_value,\n",
    "        \"max\": max_value, \n",
    "        \"mean\": mean_value, \n",
    "        \"count\": count, \n",
    "        \"std Dev\": pop_st_dev,\n",
    "        \"harmonic_mean\": harm_mean,\n",
    "        \"geometric_mean\": geo_mean,\n",
    "        \"quants\": quants,\n",
    "        \"mode\": modes\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Sort Dictionary in Order Based on Value & Return Top N Key/Value Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_from_sorted_dict(input_dict, n, desc_order=True):\n",
    "    \"\"\"\n",
    "    Sort a dictionary by its values in descending order and return the top n key-value pairs.\n",
    "    \n",
    "    Args:\n",
    "        input_dict (dict): The dictionary to sort.\n",
    "        n (int): The number of top key-value pairs to return.\n",
    "        desc (bool): True for sorting in descending order. False for ascending order.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of tuples containing the top n key-value pairs, sorted by value.\n",
    "    \"\"\"\n",
    "    if not isinstance(input_dict, dict):\n",
    "        raise ValueError(\"Input must be a dictionary.\")\n",
    "    if not isinstance(n, int) or n <= 0:\n",
    "        raise ValueError(\"The number of top items (n) must be a positive integer.\")\n",
    "    if not isinstance(desc_order, bool) or n <= 0:\n",
    "        raise ValueError(\"desc_order blue be a boolean value.\")\n",
    "    \n",
    "    # Sort the dictionary by values in descending order and extract the top n items\n",
    "    sorted_items = sorted(input_dict.items(), key=lambda item: item[1], reverse=desc_order)\n",
    "    return sorted_items[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert 'flight_distance' Attribute Values From String to Integer Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'flight_distance' attribute values from String to integer values\n",
    "for u, v, d in flightGraph.edges(data=True):\n",
    "    if 'flight_distance' in d:\n",
    "        try:\n",
    "            d['flight_distance'] = int(float(d['flight_distance']))  # Convert to float first, then integer\n",
    "        except ValueError:\n",
    "            print(f\"Invalid flight_distance on edge ({u}, {v}): {d['flight_distance']}\")\n",
    "            d['flight_distance'] = 0 # Default value for invalid data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centrality\n",
    "- Part 1\n",
    "    - Degree\n",
    "        - degree_centrality\n",
    "        - in_degree_centrality\n",
    "        - out_degree_centrality\n",
    "    - Closeness\n",
    "        - closeness_centrality\n",
    "    - (Shortest Path) Betweenness\n",
    "        - betweenness_centrality\n",
    "- Part 2\n",
    "    - Load \n",
    "        - load_centrality\n",
    "    - Harmonic Centrality\n",
    "        - harmonic_centrality\n",
    "    - Percolation\n",
    "        - percolation_centrality\n",
    "    - Trophic\n",
    "        - trophic_levels\n",
    "    - VoteRank\n",
    "        - voterank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality\n",
      "The top 12 values for Degree Centrality are:\n",
      "    [('ATL', 306.28571428571433), ('ORD', 282.31868131868134), ('DFW', 249.02197802197804), ('LAX', 193.4368131868132), ('PHX', 163.11538461538464), ('DEN', 162.1401098901099), ('IAH', 140.489010989011), ('SFO', 132.20604395604397), ('LAS', 130.01923076923077), ('DTW', 128.62637362637363), ('MSP', 121.00000000000001), ('CLT', 116.85989010989012)]\n",
      "The bottom 12 values for Degree Centrality are:\n",
      "    [('UCA', 0.0), ('TUL', 0.0), ('FOE', 0.0), ('HYS', 0.0), ('OKC', 0.0), ('LAW', 0.0), ('ISO', 0.0), ('GCK', 0.0), ('ROP', 0.0), ('ROR', 0.0), ('MHK', 0.0), ('ICT', 0.0)]\n",
      "\n",
      "In Degree Centrality\n",
      "The top 12 values for In Degree Centrality are:\n",
      "    [('ATL', 152.54395604395606), ('ORD', 141.07967032967034), ('DFW', 124.55494505494507), ('LAX', 96.65659340659342), ('PHX', 81.53296703296704), ('DEN', 81.23626373626374), ('IAH', 69.90384615384616), ('SFO', 66.03296703296704), ('LAS', 64.93131868131869), ('DTW', 64.42032967032968), ('MSP', 60.46703296703297), ('CLT', 58.35164835164836)]\n",
      "The bottom 12 values for In Degree Centrality are:\n",
      "    [('UCA', 0.0), ('SPN', 0.0), ('TUL', 0.0), ('FOE', 0.0), ('HYA', 0.0), ('HYS', 0.0), ('OKC', 0.0), ('LAW', 0.0), ('ISO', 0.0), ('GCK', 0.0), ('ROP', 0.0), ('ROR', 0.0)]\n",
      "\n",
      "Out Degree Centrality\n",
      "The top 12 values for Out Degree Centrality are:\n",
      "    [('ATL', 153.74175824175825), ('ORD', 141.239010989011), ('DFW', 124.46703296703298), ('LAX', 96.78021978021978), ('PHX', 81.58241758241759), ('DEN', 80.90384615384616), ('IAH', 70.58516483516485), ('SFO', 66.17307692307693), ('LAS', 65.08791208791209), ('DTW', 64.20604395604396), ('MSP', 60.532967032967036), ('CLT', 58.508241758241766)]\n",
      "The bottom 12 values for Out Degree Centrality are:\n",
      "    [('UCA', 0.0), ('TUL', 0.0), ('FOE', 0.0), ('RFD', 0.0), ('HYS', 0.0), ('OKC', 0.0), ('LAW', 0.0), ('ISO', 0.0), ('GCK', 0.0), ('SHD', 0.0), ('ROP', 0.0), ('ROR', 0.0)]\n",
      "\n",
      "Closeness Centrality\n",
      "The top 12 values for Closeness Centrality are:\n",
      "    [('ATL', 0.6325484534369222), ('ORD', 0.6219667878589812), ('DFW', 0.6139782236112511), ('DEN', 0.5975323783359497), ('IAH', 0.5860212467042589), ('DTW', 0.5860212467042589), ('MSP', 0.5849967340351956), ('CVG', 0.5642801549209644), ('SLC', 0.5512654561254232), ('LAX', 0.5449806707950031), ('CLT', 0.5432112530326817), ('PHX', 0.5379712730998905)]\n",
      "The bottom 12 values for Closeness Centrality are:\n",
      "    [('UCA', 0.0), ('SPN', 0.0), ('TUL', 0.0), ('FOE', 0.0), ('HYA', 0.0), ('HYS', 0.0), ('OKC', 0.0), ('LAW', 0.0), ('ISO', 0.0), ('GCK', 0.0), ('ROP', 0.0), ('ROR', 0.0)]\n",
      "\n",
      "Betweenness Centrality\n",
      "The top 12 values for Betweenness Centrality are:\n",
      "    [('ATL', 0.1354908562091235), ('DFW', 0.11949508545338032), ('ORD', 0.108592409347137), ('DEN', 0.10173297910807282), ('MSP', 0.09409342896161436), ('ANC', 0.07801682011786822), ('IAH', 0.07795951643379752), ('SLC', 0.07721616384934679), ('DTW', 0.061674894020706285), ('LAX', 0.05023816025015272), ('SFO', 0.04945065464065719), ('SEA', 0.04451482523993931)]\n",
      "The bottom 12 values for Betweenness Centrality are:\n",
      "    [('UCA', 0.0), ('TUL', 0.0), ('FOE', 0.0), ('HYS', 0.0), ('OKC', 0.0), ('LAW', 0.0), ('ISO', 0.0), ('GCK', 0.0), ('ROP', 0.0), ('ROR', 0.0), ('MHK', 0.0), ('ICT', 0.0)]\n",
      "\n",
      "Weighted Closeness Centrality\n",
      "The top 12 values for Weighted Closeness Centrality are:\n",
      "    [('UNKNOWN(ATL)', 0.6325484534369222), ('UNKNOWN(ORD)', 0.6219667878589812), ('UNKNOWN(DFW)', 0.6139782236112511), ('UNKNOWN(DEN)', 0.5975323783359497), ('UNKNOWN(IAH)', 0.5860212467042589), ('UNKNOWN(DTW)', 0.5860212467042589), ('UNKNOWN(MSP)', 0.5849967340351956), ('UNKNOWN(CVG)', 0.5642801549209644), ('UNKNOWN(SLC)', 0.5512654561254232), ('UNKNOWN(LAX)', 0.5449806707950031), ('UNKNOWN(CLT)', 0.5432112530326817), ('UNKNOWN(PHX)', 0.5379712730998905)]\n",
      "The bottom 12 values for Weighted Closeness Centrality are:\n",
      "    [('UNKNOWN(UCA)', 0.0), ('UNKNOWN(SPN)', 0.0), ('UNKNOWN(TUL)', 0.0), ('UNKNOWN(FOE)', 0.0), ('UNKNOWN(HYA)', 0.0), ('UNKNOWN(HYS)', 0.0), ('UNKNOWN(OKC)', 0.0), ('UNKNOWN(LAW)', 0.0), ('UNKNOWN(ISO)', 0.0), ('UNKNOWN(GCK)', 0.0), ('UNKNOWN(ROP)', 0.0), ('UNKNOWN(ROR)', 0.0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The degree centrality for a node is the fraction of nodes it is connected to.\n",
    "deg_cent = nx.degree_centrality(flightGraph) \n",
    "\n",
    "# The in-degree centrality for a node is the fraction of nodes its incoming edges are connected to.\n",
    "id_cent = nx.in_degree_centrality(flightGraph)\n",
    "\n",
    "# The out-degree centrality for a node is the fraction of nodes its outgoing edges are connected to.\n",
    "od_cent = nx.out_degree_centrality(flightGraph)\n",
    "\n",
    "# Closeness\n",
    "closeness_centrality = nx.closeness_centrality(\n",
    "    flightGraph,\n",
    "    wf_improved=True\n",
    ")\n",
    "\n",
    "# (Shortest Path) Betweenness\n",
    "bc = nx.betweenness_centrality(\n",
    "    flightGraph, \n",
    "    endpoints=True\n",
    "    )\n",
    "\n",
    "# Weighted Closeness Centrality\n",
    "weighted_closeness_centrality = nx.closeness_centrality(\n",
    "    flightGraph, \n",
    "    distance=\"flight_distance\",\n",
    "    wf_improved=True\n",
    "    )\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Convert the keys from the node_id's to their respective airport_code's\n",
    "deg_cent = convert_output_keys_to_airport_codes(\n",
    "    deg_cent, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "id_cent = convert_output_keys_to_airport_codes(\n",
    "    id_cent, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "od_cent = convert_output_keys_to_airport_codes(\n",
    "    od_cent,\n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "closeness_centrality = convert_output_keys_to_airport_codes(\n",
    "    closeness_centrality, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "bc = convert_output_keys_to_airport_codes(\n",
    "    bc, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "weighted_closeness_centrality = convert_output_keys_to_airport_codes(\n",
    "    closeness_centrality, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Return the Top 12 results (after they are sorted)\n",
    "n = 12\n",
    "\n",
    "centrality_outputs = [\n",
    "    deg_cent, \n",
    "    id_cent,\n",
    "    od_cent,\n",
    "    closeness_centrality,\n",
    "    bc,\n",
    "    weighted_closeness_centrality\n",
    "]\n",
    "\n",
    "centrality_output_names = [\n",
    "    \"Degree Centrality\",\n",
    "    \"In Degree Centrality\",\n",
    "    \"Out Degree Centrality\",\n",
    "    \"Closeness Centrality\",\n",
    "    \"Betweenness Centrality\",\n",
    "    \"Weighted Closeness Centrality\"\n",
    "]\n",
    "\n",
    "# loop through each of the values above to get the top & bottom 12 results (after sorted)\n",
    "for co in range(len(centrality_outputs)):\n",
    "    col_name = centrality_output_names[co]\n",
    "    print(col_name)\n",
    "    top_12_values = get_top_n_from_sorted_dict(centrality_outputs[co], n, desc_order=True)\n",
    "    bottom_12_values = get_top_n_from_sorted_dict(centrality_outputs[co], n, desc_order=False)\n",
    "    \n",
    "    print(f\"\"\"The top {n} values for {col_name} are:\n",
    "    {top_12_values}\n",
    "The bottom {n} values for {col_name} are:\n",
    "    {bottom_12_values}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Centrality\n",
      "The top 12 values for Load Centrality are:\n",
      "    [('ATL', 0.1306638522176983), ('DFW', 0.11465289879868668), ('ORD', 0.10376748548014621), ('DEN', 0.09713155860796076), ('MSP', 0.089451156218076), ('ANC', 0.07299275968797214), ('IAH', 0.07294982747096553), ('SLC', 0.07219482437038995), ('DTW', 0.056379186754066134), ('LAX', 0.04487316911621955), ('SFO', 0.044040292572139615), ('SEA', 0.0385166472597061)]\n",
      "The bottom 12 values for Load Centrality are:\n",
      "    [('RDM', 0.0), ('HIB', 0.0), ('UCA', 0.0), ('HDN', 0.0), ('MAZ', 0.0), ('CDC', 0.0), ('PSC', 0.0), ('AGS', 0.0), ('PLN', 0.0), ('LMT', 0.0), ('BTM', 0.0), ('CPR', 0.0)]\n",
      "\n",
      "Harmonic Centrality\n",
      "The top 12 values for Harmonic Centrality are:\n",
      "    [('DTW', 0.5610976360067543), ('ORD', 0.5591878186550777), ('CVG', 0.555109308341165), ('ATL', 0.5297362690517526), ('DAY', 0.5260081310300452), ('TOL', 0.5233120360309452), ('CLT', 0.5178371226570421), ('MKE', 0.5163258740670005), ('IAH', 0.5156080989895292), ('LEX', 0.512448652631544), ('PIT', 0.5105678756851603), ('CMH', 0.5104961869714941)]\n",
      "The bottom 12 values for Harmonic Centrality are:\n",
      "    [('ISO', 0), ('LAW', 0), ('DET', 0), ('SPN', 0), ('MHK', 0), ('FOE', 0), ('GCK', 0), ('OKC', 0), ('TUL', 0), ('UCA', 0), ('ICT', 0), ('HYS', 0)]\n",
      "\n",
      "Percolation\n",
      "The top 12 values for Percolation are:\n",
      "    [('ATL', 0.13095476611225254), ('DFW', 0.11487086438815808), ('ORD', 0.10390811844110923), ('DEN', 0.09701089519797286), ('MSP', 0.08932925386613448), ('ANC', 0.07316406866512246), ('IAH', 0.07310644925827456), ('SLC', 0.0723590010672979), ('DTW', 0.056732104407645645), ('LAX', 0.04523235832981629), ('SFO', 0.04444051384643923), ('SEA', 0.03947748979337581)]\n",
      "The bottom 12 values for Percolation are:\n",
      "    [('RDM', 0.0), ('HIB', 0.0), ('UCA', 0.0), ('HDN', 0.0), ('MAZ', 0.0), ('CDC', 0.0), ('PSC', 0.0), ('AGS', 0.0), ('PLN', 0.0), ('LMT', 0.0), ('BTM', 0.0), ('CPR', 0.0)]\n",
      "\n",
      "Trophic Level\n",
      "The top 12 values for Trophic Level are:\n",
      "    [('PSG', 387728.7952600705), ('WRG', 387728.6506266859), ('DVL', 387728.6109646074), ('YAK', 387728.4958899709), ('PIB', 387728.14659196546), ('CDV', 387728.0877407893), ('GST', 387727.9234440974), ('IMT', 387727.8715574902), ('BRW', 387727.74601643515), ('KSM', 387727.7023036922), ('INL', 387727.6645411903), ('SIT', 387727.6542169021)]\n",
      "The bottom 12 values for Trophic Level are:\n",
      "    [('UCA', 1), ('SPN', 1), ('TUL', 1), ('FOE', 1), ('HYA', 1), ('HYS', 1), ('OKC', 1), ('LAW', 1), ('ISO', 1), ('GCK', 1), ('ROP', 1), ('ROR', 1)]\n",
      "\n",
      "The Local Reaching Centrality is: 0.9587912087912088.\n",
      "\n",
      "There are 126 airports in the Vote Rank output. They are (in order): ['ATL', 'ORD', 'DFW', 'LAX', 'DEN', 'IAH', 'DTW', 'SLC', 'MSP', 'CLT', 'SFO', 'PHX', 'HNL', 'SEA', 'BWI', 'HOU', 'PIT', 'CVG', 'EWR', 'ANC', 'MCO', 'DAL', 'JFK', 'STL', 'LAS', 'PHL', 'IAD', 'MEM', 'LGA', 'PDX', 'MIA', 'BOS', 'MDW', 'JNU', 'CLE', 'FLL', 'TPA', 'OAK', 'AUS', 'DCA', 'PBI', 'ABQ', 'OGG', 'FAI', 'KTN', 'BNA', 'OTZ', 'SJU', 'RNO', 'SAT', 'PSG', 'SMF', 'GTF', 'ELP', 'GEG', 'BHM', 'MKE', 'YAK', 'RSW', 'SHV', 'SJC', 'MDT', 'BTR', 'SCC', 'PWM', 'STT', 'ITH', 'PVD', 'ACV', 'JAN', 'BIL', 'MSY', 'SDF', 'ROC', 'SAN', 'IND', 'FCA', 'RKS', 'JAX', 'AKN', 'MGM', 'HSV', 'MQT', 'PNS', 'AZO', 'FAT', 'JMS', 'RHI', 'TOL', 'JAC', 'MEI', 'MYR', 'RDU', 'INL', 'GSO', 'MCI', 'AGS', 'MFR', 'YUM', 'SWF', 'HPN', 'AEX', 'ITO', 'CHS', 'RST', 'AVP', 'OMA', 'TTN', 'CWA', 'BOI', 'ANI', 'ROA', 'DSM', 'SNA', 'BTV', 'PIA', 'BUF', 'BDL', 'LNY', 'APN', 'SPN', 'CDC', 'MOB', 'GSP', 'EVV', 'CMH'].\n"
     ]
    }
   ],
   "source": [
    "source = get_node_by_attribute(flightGraph, \"airport_code\", \"MKE\")\n",
    "\n",
    "# Load Centrality\n",
    "lc = nx.load_centrality(\n",
    "    flightGraph, \n",
    "    cutoff=5,\n",
    "    normalized=True\n",
    "    )\n",
    "\n",
    "# Harmonic Centrality\n",
    "hc = nx.harmonic_centrality(\n",
    "    flightGraph,\n",
    "    distance=\"flight_distance\"\n",
    "    )\n",
    "\n",
    "# Reaching\n",
    "lrc = nx.local_reaching_centrality(\n",
    "    flightGraph, \n",
    "    v=source, \n",
    "    paths=None, \n",
    "    normalized=True\n",
    "    )\n",
    "\n",
    "# Percolation\n",
    "pc = nx.percolation_centrality(flightGraph)\n",
    "\n",
    "# Trophic\n",
    "tl = nx.trophic_levels(flightGraph)\n",
    "\n",
    "# VoteRank\n",
    "vr = nx.voterank(flightGraph)\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Convert the keys from the node_id's to their respective airport_code's\n",
    "lc = convert_output_keys_to_airport_codes(\n",
    "    lc, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "hc = convert_output_keys_to_airport_codes(\n",
    "    hc, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "pc = convert_output_keys_to_airport_codes(\n",
    "    pc, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "tl = convert_output_keys_to_airport_codes(\n",
    "    tl,\n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "vr = [id_to_airport_code_mapping_dict.get(node_id, node_id) for node_id in vr]\n",
    "\n",
    "### ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# Return the Top 12 results (after they are sorted)\n",
    "n = 12\n",
    "\n",
    "centrality_outputs = [\n",
    "    lc, \n",
    "    hc,\n",
    "    pc,\n",
    "    tl\n",
    "]\n",
    "\n",
    "centrality_output_names = [\n",
    "    \"Load Centrality\",\n",
    "    \"Harmonic Centrality\",\n",
    "    \"Percolation\",\n",
    "    \"Trophic Level\"\n",
    "]\n",
    "\n",
    "# loop through each of the values above to get the top & bottom 12 results (after sorted)\n",
    "for co in range(len(centrality_outputs)):\n",
    "    col_name = centrality_output_names[co]\n",
    "    print(col_name)\n",
    "    top_12_values = get_top_n_from_sorted_dict(centrality_outputs[co], n, desc_order=True)\n",
    "    bottom_12_values = get_top_n_from_sorted_dict(centrality_outputs[co], n, desc_order=False)\n",
    "    \n",
    "    print(f\"\"\"The top {n} values for {col_name} are:\n",
    "    {top_12_values}\n",
    "The bottom {n} values for {col_name} are:\n",
    "    {bottom_12_values}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"The Local Reaching Centrality is: {lrc}.\\n\")\n",
    "\n",
    "print(f\"There are {len(vr)} airports in the Vote Rank output. They are (in order): {vr}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Create Maps Between Ids & Attribute Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering\n",
    "- square_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 12 values for Square Clustering are:\n",
      "    [('LCH', 0.7485029940119761), ('LRD', 0.7485029940119761), ('BRO', 0.7485029940119761), ('ILE', 0.7485029940119761), ('TXK', 0.7485029940119761), ('CLL', 0.7485029940119761), ('SJT', 0.7485029940119761), ('ABI', 0.7485029940119761), ('BPT', 0.7485029940119761), ('ACT', 0.7485029940119761), ('MVY', 0.6853932584269663), ('SMX', 0.6761904761904762)]\n",
      "The bottom 12 values for Square Clustering are:\n",
      "    [('UCA', 0), ('MAZ', 0), ('ANI', 0), ('BTM', 0), ('UTM', 0), ('DHN', 0), ('MKG', 0), ('LNY', 0), ('EWN', 0), ('MWH', 0), ('HOB', 0), ('PIH', 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sclust = nx.square_clustering(flightGraph)\n",
    "sclust = convert_output_keys_to_airport_codes(\n",
    "    sclust, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "# Return the Top 12 results (after they are sorted)\n",
    "n = 12\n",
    "col_name = \"Square Clustering\"\n",
    "\n",
    "top_12_values = get_top_n_from_sorted_dict(\n",
    "    sclust, \n",
    "    n, \n",
    "    desc_order=True\n",
    "    )\n",
    "\n",
    "bottom_12_values = get_top_n_from_sorted_dict(\n",
    "    sclust, \n",
    "    n, \n",
    "    desc_order=False\n",
    "    )\n",
    "\n",
    "print(f\"\"\"The top {n} values for {col_name} are:\n",
    "    {top_12_values}\n",
    "The bottom {n} values for {col_name} are:\n",
    "    {bottom_12_values}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communities\n",
    "- Label Propagation\n",
    "    - asyn_lpa_communities\n",
    "    - fast_label_propagation_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asynchronous LPA Communities:\n",
      "Top Level Communities (348): \n",
      "      ['EWR', 'AVL', 'MOB', 'MOT', 'CRW', 'GEG', 'LGB', 'ELP', 'UTM', 'MEI', 'DFW', 'RIC', 'HLN', 'FAR', 'LAS', 'ECP', 'OXR', 'ABY', 'FCA', 'CYS', 'JNU', 'IAH', 'DHN', 'WYS', 'CLD', 'BOS', 'MIA', 'BGR', 'LMT', 'BPT', 'EVV', 'AKN', 'VLD', 'SBA', 'DCA', 'PAH', 'CNY', 'MWH', 'BIS', 'CIC', 'PUB', 'SAT', 'SFO', 'LWS', 'ERI', 'SRQ', 'CPR', 'JAX', 'MYR', 'ASE', 'LFT', 'MFR', 'ORF', 'PIH', 'BIL', 'SIT', 'SPS', 'ANC', 'PIE', 'ABI', 'ADQ', 'CMH', 'HOB', 'MOD', 'STX', 'HIB', 'RDM', 'MDT', 'MIB', 'SUX', 'ACT', 'BTM', 'OTZ', 'LIH', 'SYR', 'RNO', 'LGA', 'SEA', 'STL', 'SAF', 'PIA', 'BUR', 'MVY', 'SCE', 'ALB', 'EYW', 'SPN', 'SMF', 'CVG', 'GTF', 'PBG', 'SJC', 'FNT', 'SDF', 'BRW', 'AMA', 'SLC', 'VPS', 'GSO', 'MSY', 'MCN', 'DLG', 'CMI', 'VEL', 'MGM', 'MSN', 'GGG', 'HPN', 'AVP', 'SPI', 'JAC', 'MKG', 'LBE', 'CLE', 'GRI', 'CEC', 'MCO', 'CLL', 'EGE', 'BUF', 'FLL', 'TPA', 'FWA', 'STC', 'BKG', 'STT', 'MKK', 'ELM', 'PSG', 'MSP', 'AEX', 'SUN', 'INL', 'MQT', 'GRR', 'PLN', 'ESC', 'GPT', 'GTR', 'PIT', 'GCC', 'IND', 'ISP', 'ILM', 'DAL', 'HVN', 'EAU', 'CID', 'JFK', 'SHV', 'TXK', 'APN', 'CAK', 'CRP', 'BET', 'BHM', 'JMS', 'FLO', 'HOU', 'LAX', 'SMX', 'MFE', 'DTW', 'AZA', 'SCC', 'ROC', 'CHS', 'SAN', 'PDX', 'FLG', 'BJI', 'AGS', 'YUM', 'DRT', 'FAI', 'SWF', 'ALO', 'DUT', 'FSM', 'BOI', 'DBQ', 'TTN', 'EKO', 'PPG', 'MCI', 'PHL', 'BWI', 'MTJ', 'ATL', 'BGM', 'TEX', 'OMA', 'CLT', 'IDA', 'BFL', 'VIS', 'CDC', 'GUM', 'JAN', 'OAK', 'ROW', 'COU', 'RAP', 'SBN', 'TRI', 'FSD', 'OTH', 'DAB', 'DVL', 'RHI', 'TVC', 'XNA', 'UST', 'PFN', 'AZO', 'RSW', 'IYK', 'SJT', 'GJT', 'FAY', 'JLN', 'MEM', 'FAT', 'CMX', 'EUG', 'BMI', 'PSC', 'DIK', 'BZN', 'PVD', 'PIB', 'HSV', 'ABE', 'CWA', 'EWN', 'COD', 'MBS', 'LAR', 'HNL', 'LSE', 'BQK', 'PWM', 'DRO', 'MHT', 'RDD', 'PSE', 'GNV', 'VCT', 'CIU', 'TOL', 'GSP', 'LNK', 'APF', 'ORD', 'GRK', 'LCH', 'MRY', 'GFK', 'PSP', 'TLH', 'COS', 'KTN', 'LEX', 'SNA', 'LBB', 'BTV', 'ABR', 'RST', 'LWB', 'DAY', 'HTS', 'HRL', 'ITH', 'DLH', 'CHA', 'GRB', 'TYS', 'MAZ', 'ORH', 'IAG', 'ANI', 'MSO', 'LNY', 'ISN', 'ATW', 'PHF', 'KSM', 'MDW', 'CAE', 'BDL', 'SAV', 'ART', 'MAF', 'DEN', 'BRO', 'BQN', 'ADK', 'IMT', 'SJU', 'OME', 'HDN', 'DSM', 'MLI', 'AUS', 'MMH', 'MKE', 'OGG', 'ACY', 'IPL', 'BLI', 'GUC', 'SGF', 'LAN', 'MLB', 'GST', 'ACK', 'KOA', 'HYA', 'PBI', 'ILG', 'RKS', 'EFD', 'PHX', 'OAJ', 'LYH', 'TUS', 'ILE', 'ABQ', 'RDU', 'ONT', 'ITO', 'IAD', 'TYR', 'WRG', 'BNA', 'TWF', 'PNS', 'ACV', 'SBP', 'LIT', 'MLU', 'ROA', 'BRD', 'CHO', 'BTR', 'LRD', 'CSG', 'SGU']\n",
      "      \n",
      "Level 2 communities (1): ['UCA']\n",
      "              \n",
      "Level 3 communities (1): ['TUL']\n",
      "              \n",
      "Level 4 communities (1): ['FOE']\n",
      "              \n",
      "Level 5 communities (1): ['RFD']\n",
      "              \n",
      "Level 6 communities (1): ['HYS']\n",
      "              \n",
      "Level 7 communities (1): ['OKC']\n",
      "              \n",
      "Level 8 communities (1): ['LAW']\n",
      "              \n",
      "Level 9 communities (1): ['ISO']\n",
      "              \n",
      "Level 10 communities (1): ['GCK']\n",
      "              \n",
      "Level 11 communities (2): ['YAK', 'CDV']\n",
      "              \n",
      "Level 12 communities (1): ['SHD']\n",
      "              \n",
      "Level 13 communities (1): ['ROP']\n",
      "              \n",
      "Level 14 communities (1): ['ROR']\n",
      "              \n",
      "Level 15 communities (1): ['MHK']\n",
      "              \n",
      "Level 16 communities (1): ['ICT']\n",
      "              \n",
      "Level 17 communities (1): ['DET']\n",
      "              \n",
      "Fast Label Propagation Communities\n",
      "Top Level Communities (350): \n",
      "      ['EWR', 'AVL', 'MOB', 'MOT', 'CRW', 'GEG', 'LGB', 'ELP', 'UTM', 'MEI', 'DFW', 'RIC', 'HLN', 'FAR', 'LAS', 'ECP', 'OXR', 'ABY', 'FCA', 'CYS', 'JNU', 'IAH', 'DHN', 'WYS', 'CLD', 'BOS', 'MIA', 'BGR', 'LMT', 'BPT', 'EVV', 'AKN', 'VLD', 'SBA', 'DCA', 'PAH', 'CNY', 'MWH', 'BIS', 'CIC', 'PUB', 'SAT', 'SFO', 'LWS', 'ERI', 'SRQ', 'CPR', 'JAX', 'MYR', 'ASE', 'LFT', 'MFR', 'ORF', 'PIH', 'BIL', 'SIT', 'SPS', 'ANC', 'PIE', 'ABI', 'ADQ', 'CMH', 'HOB', 'MOD', 'STX', 'HIB', 'RDM', 'MDT', 'MIB', 'SUX', 'ACT', 'BTM', 'OTZ', 'LIH', 'SYR', 'RNO', 'LGA', 'SEA', 'STL', 'SAF', 'PIA', 'BUR', 'MVY', 'SCE', 'ALB', 'EYW', 'SPN', 'SMF', 'CVG', 'GTF', 'PBG', 'SJC', 'FNT', 'SDF', 'BRW', 'AMA', 'SLC', 'VPS', 'GSO', 'MSY', 'MCN', 'DLG', 'CMI', 'VEL', 'MGM', 'MSN', 'GGG', 'HPN', 'AVP', 'SPI', 'JAC', 'MKG', 'LBE', 'CLE', 'GRI', 'CEC', 'MCO', 'CLL', 'EGE', 'BUF', 'FLL', 'TPA', 'FWA', 'STC', 'BKG', 'STT', 'MKK', 'ELM', 'PSG', 'MSP', 'AEX', 'SUN', 'INL', 'MQT', 'GRR', 'PLN', 'ESC', 'GPT', 'GTR', 'PIT', 'GCC', 'IND', 'ISP', 'ILM', 'DAL', 'HVN', 'EAU', 'CID', 'JFK', 'SHV', 'TXK', 'APN', 'CAK', 'CRP', 'BET', 'BHM', 'JMS', 'FLO', 'HOU', 'LAX', 'SMX', 'MFE', 'DTW', 'AZA', 'SCC', 'ROC', 'CHS', 'SAN', 'PDX', 'FLG', 'BJI', 'AGS', 'YUM', 'DRT', 'FAI', 'SWF', 'ALO', 'DUT', 'FSM', 'BOI', 'DBQ', 'TTN', 'EKO', 'PPG', 'MCI', 'PHL', 'BWI', 'MTJ', 'ATL', 'BGM', 'TEX', 'OMA', 'CLT', 'IDA', 'BFL', 'VIS', 'CDC', 'GUM', 'JAN', 'OAK', 'ROW', 'COU', 'RAP', 'SBN', 'TRI', 'FSD', 'OTH', 'DAB', 'DVL', 'RHI', 'TVC', 'XNA', 'UST', 'PFN', 'AZO', 'RSW', 'IYK', 'SJT', 'GJT', 'FAY', 'JLN', 'MEM', 'FAT', 'CMX', 'EUG', 'BMI', 'PSC', 'DIK', 'BZN', 'PVD', 'PIB', 'HSV', 'ABE', 'CWA', 'EWN', 'COD', 'MBS', 'LAR', 'HNL', 'LSE', 'BQK', 'PWM', 'DRO', 'MHT', 'RDD', 'PSE', 'GNV', 'VCT', 'CIU', 'TOL', 'GSP', 'LNK', 'APF', 'ORD', 'GRK', 'LCH', 'MRY', 'GFK', 'PSP', 'TLH', 'COS', 'KTN', 'LEX', 'SNA', 'LBB', 'BTV', 'ABR', 'RST', 'LWB', 'DAY', 'HTS', 'HRL', 'ITH', 'DLH', 'CHA', 'GRB', 'TYS', 'MAZ', 'ORH', 'IAG', 'ANI', 'MSO', 'LNY', 'ISN', 'ATW', 'PHF', 'KSM', 'MDW', 'CAE', 'BDL', 'SAV', 'ART', 'MAF', 'DEN', 'BRO', 'BQN', 'ADK', 'IMT', 'SJU', 'OME', 'HDN', 'DSM', 'MLI', 'AUS', 'MMH', 'MKE', 'OGG', 'ACY', 'IPL', 'BLI', 'GUC', 'SGF', 'LAN', 'MLB', 'GST', 'ACK', 'KOA', 'HYA', 'PBI', 'ILG', 'RKS', 'EFD', 'PHX', 'OAJ', 'LYH', 'TUS', 'ILE', 'ABQ', 'RDU', 'ONT', 'ITO', 'IAD', 'TYR', 'WRG', 'BNA', 'TWF', 'PNS', 'ACV', 'SBP', 'LIT', 'MLU', 'ROA', 'BRD', 'CHO', 'BTR', 'LRD', 'CSG', 'SGU']\n",
      "      \n",
      "Level 2 communities (1): ['UCA']\n",
      "Level 3 communities (1): ['TUL']\n",
      "Level 4 communities (1): ['FOE']\n",
      "Level 5 communities (1): ['HYS']\n",
      "Level 6 communities (1): ['OKC']\n",
      "Level 7 communities (1): ['LAW']\n",
      "Level 8 communities (1): ['ISO']\n",
      "Level 9 communities (1): ['GCK']\n",
      "Level 10 communities (2): ['YAK', 'CDV']\n",
      "Level 11 communities (1): ['ROP']\n",
      "Level 12 communities (1): ['ROR']\n",
      "Level 13 communities (1): ['MHK']\n",
      "Level 14 communities (1): ['ICT']\n",
      "Level 15 communities (1): ['DET']\n"
     ]
    }
   ],
   "source": [
    "# Label propagation\n",
    "# ** Label propagation community detection algorithms.\n",
    "\n",
    "a_lpa_comm = nx.community.asyn_lpa_communities(\n",
    "    flightGraph, \n",
    "    weight=\"flight_distance\",\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "flpc = nx.community.fast_label_propagation_communities(\n",
    "    flightGraph,\n",
    "    weight=\"flight_distance\",\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "# Print Results\n",
    "print(f\"Asynchronous LPA Communities:\")\n",
    "\n",
    "top_level_comms_a_lpa_comm = list(next(a_lpa_comm))\n",
    "print(f\"\"\"Top Level Communities ({len(top_level_comms_a_lpa_comm)}): \n",
    "      {[id_to_airport_code_mapping_dict.get(node_id, node_id) for node_id in top_level_comms_a_lpa_comm]}\n",
    "      \"\"\")\n",
    "\n",
    "try:\n",
    "    # Loop through all levels of communities\n",
    "    level = 2\n",
    "    while True:\n",
    "        a_lpa_comm_communities = list(next(a_lpa_comm))\n",
    "        print(f\"\"\"Level {level} communities ({len(a_lpa_comm_communities)}): {[id_to_airport_code_mapping_dict.get(node_id, node_id) for node_id in a_lpa_comm_communities]}\n",
    "              \"\"\")\n",
    "        level += 1\n",
    "except StopIteration:\n",
    "    pass\n",
    "\n",
    "print(\"Fast Label Propagation Communities\")\n",
    "\n",
    "top_level_comms_flpc = list(next(flpc))\n",
    "print(f\"\"\"Top Level Communities ({len(top_level_comms_flpc)}): \n",
    "      {[id_to_airport_code_mapping_dict.get(node_id, node_id) for node_id in top_level_comms_a_lpa_comm]}\n",
    "      \"\"\")\n",
    "\n",
    "try:\n",
    "    # Loop through all levels of communities\n",
    "    level = 2\n",
    "    while True:\n",
    "        flpc_communities = list(next(flpc))\n",
    "        print(f\"\"\"Level {level} communities ({len(flpc_communities)}): {[id_to_airport_code_mapping_dict.get(node_id, node_id) for node_id in flpc_communities]}\"\"\")\n",
    "        level += 1\n",
    "except StopIteration:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components\n",
    "- Strong Connectivity\n",
    "    - is_strongly_connected\n",
    "    - number_strongly_connected_components\n",
    "    - strongly_connected_components\n",
    "    - kosaraju_strongly_connected_components\n",
    "- Weak Connectivity\n",
    "    - is_weakly_connected\n",
    "    - number_weakly_connected_components\n",
    "    - weakly_connected_components\n",
    "- Attracting Components \n",
    "    - is_attracting_component\n",
    "    - number_attracting_components\n",
    "    - attracting_components\n",
    "- Semiconnectedness\n",
    "    -  is_semiconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Strongly Connected Components (SCC): [{'GNV', 'DRO', 'ADK', 'ELP', 'FLG', 'AMA', 'TLH', 'FAR', 'JMS', 'ABE', 'LIH', 'SCC', 'LSE', 'PPG', 'BRO', 'SCE', 'DEN', 'RHI', 'GJT', 'RDU', 'IYK', 'APF', 'FWA', 'OAK', 'ORD', 'SBA', 'TYR', 'SGF', 'JAC', 'AUS', 'ISN', 'ANC', 'BJI', 'LFT', 'LWS', 'MOD', 'CIU', 'MCN', 'AGS', 'ISP', 'MKK', 'GST', 'GRB', 'FLO', 'SUN', 'ONT', 'PSG', 'ITH', 'CDC', 'MSO', 'BKG', 'GPT', 'SYR', 'BUR', 'CHA', 'ITO', 'GTR', 'JLN', 'MIA', 'INL', 'EWN', 'MVY', 'BTV', 'VCT', 'FCA', 'LGA', 'BRW', 'CYS', 'DAL', 'BUF', 'FNT', 'SWF', 'EYW', 'RIC', 'MHT', 'HPN', 'OTH', 'BDL', 'WYS', 'ADQ', 'SAF', 'CVG', 'SMF', 'GUC', 'MCI', 'DUT', 'ROC', 'VPS', 'CLT', 'ASE', 'JNU', 'ESC', 'GGG', 'STX', 'MLB', 'GRI', 'PDX', 'PFN', 'IND', 'WRG', 'MDW', 'PBI', 'STT', 'HVN', 'CHS', 'IAD', 'ALB', 'LYH', 'CAE', 'TOL', 'VEL', 'MQT', 'BTR', 'HIB', 'IAH', 'KTN', 'ILE', 'MLU', 'SBN', 'SJC', 'PIH', 'FAI', 'RDD', 'MAF', 'CWA', 'ABR', 'DBQ', 'IAG', 'MTJ', 'EAU', 'YAK', 'ABI', 'SMX', 'KOA', 'MSY', 'DFW', 'SJU', 'CLD', 'BNA', 'HOU', 'PHF', 'DIK', 'BQK', 'BIS', 'MIB', 'LNK', 'CSG', 'IPL', 'MRY', 'MWH', 'PLN', 'CRW', 'OMA', 'MAZ', 'MOT', 'TTN', 'SBP', 'MSP', 'PIT', 'TEX', 'HTS', 'MGM', 'LIT', 'AEX', 'PIA', 'APN', 'OGG', 'EVV', 'MLI', 'FSM', 'LAR', 'EFD', 'ATL', 'MCO', 'ECP', 'PBG', 'CDV', 'TWF', 'XNA', 'SAT', 'BWI', 'BET', 'DAY', 'CMX', 'OTZ', 'GCC', 'SGU', 'SAV', 'VIS', 'PAH', 'CMH', 'LAS', 'TUS', 'SNA', 'OME', 'JAX', 'PIE', 'RSW', 'ILM', 'DVL', 'MFR', 'PUB', 'SJT', 'MKG', 'JFK', 'STL', 'CIC', 'CAK', 'SAN', 'CLE', 'STC', 'EGE', 'PHL', 'ORH', 'ILG', 'HDN', 'CLL', 'AZA', 'GFK', 'BHM', 'DSM', 'LNY', 'DAB', 'MYR', 'DTW', 'SFO', 'MFE', 'TPA', 'ACT', 'SDF', 'CEC', 'DLG', 'TVC', 'RNO', 'AZO', 'PNS', 'PWM', 'LGB', 'MMH', 'MEI', 'HRL', 'BGM', 'LWB', 'BTM', 'BOI', 'FAY', 'KSM', 'ABQ', 'PSP', 'PHX', 'ORF', 'BGR', 'TXK', 'RKS', 'RDM', 'MOB', 'ELM', 'HLN', 'BIL', 'ABY', 'LEX', 'ROW', 'UST', 'BFL', 'UTM', 'CPR', 'BOS', 'CHO', 'IDA', 'GEG', 'COD', 'SPS', 'AVL', 'SIT', 'PSC', 'ART', 'LAN', 'GTF', 'BRD', 'COU', 'FAT', 'SRQ', 'GRK', 'ATW', 'EWR', 'ACK', 'BPT', 'MSN', 'DHN', 'LMT', 'ALO', 'SUX', 'EKO', 'MDT', 'CNY', 'SHV', 'HOB', 'LAX', 'GUM', 'GRR', 'CRP', 'LRD', 'LBB', 'EUG', 'TRI', 'CMI', 'DLH', 'OXR', 'DRT', 'AKN', 'GSO', 'VLD', 'GSP', 'PIB', 'TYS', 'COS', 'MEM', 'AVP', 'BLI', 'MBS', 'LCH', 'ACY', 'BZN', 'YUM', 'SEA', 'PSE', 'IMT', 'ERI', 'ROA', 'RST', 'RAP', 'ACV', 'HSV', 'PVD', 'CID', 'SLC', 'DCA', 'FLL', 'OAJ', 'SPI', 'BMI', 'HNL', 'JAN', 'ANI', 'LBE', 'MKE', 'BQN', 'FSD'}, {'SHD'}, {'RFD'}, {'UCA'}, {'SPN'}, {'TUL'}, {'FOE'}, {'HYA'}, {'HYS'}, {'OKC'}, {'LAW'}, {'ISO'}, {'GCK'}, {'ROP'}, {'ROR'}, {'MHK'}, {'ICT'}, {'DET'}]\n",
      "Converted Kosaraju SCC: [{'GNV', 'DRO', 'ADK', 'ELP', 'FLG', 'AMA', 'TLH', 'FAR', 'JMS', 'ABE', 'LIH', 'SCC', 'LSE', 'PPG', 'BRO', 'SCE', 'DEN', 'RHI', 'GJT', 'RDU', 'IYK', 'APF', 'FWA', 'OAK', 'ORD', 'SBA', 'TYR', 'SGF', 'JAC', 'AUS', 'ISN', 'ANC', 'BJI', 'LFT', 'LWS', 'MOD', 'CIU', 'MCN', 'AGS', 'ISP', 'MKK', 'GST', 'GRB', 'FLO', 'SUN', 'ONT', 'PSG', 'ITH', 'CDC', 'MSO', 'BKG', 'GPT', 'SYR', 'BUR', 'CHA', 'ITO', 'GTR', 'JLN', 'MIA', 'INL', 'EWN', 'MVY', 'BTV', 'VCT', 'FCA', 'LGA', 'BRW', 'CYS', 'DAL', 'BUF', 'FNT', 'SWF', 'EYW', 'RIC', 'MHT', 'HPN', 'OTH', 'BDL', 'WYS', 'ADQ', 'SAF', 'CVG', 'SMF', 'GUC', 'MCI', 'DUT', 'ROC', 'VPS', 'CLT', 'ASE', 'JNU', 'ESC', 'GGG', 'STX', 'MLB', 'GRI', 'PDX', 'PFN', 'IND', 'WRG', 'MDW', 'PBI', 'STT', 'HVN', 'CHS', 'IAD', 'ALB', 'LYH', 'CAE', 'TOL', 'VEL', 'MQT', 'BTR', 'HIB', 'IAH', 'KTN', 'ILE', 'MLU', 'SBN', 'SJC', 'PIH', 'FAI', 'RDD', 'MAF', 'CWA', 'ABR', 'DBQ', 'IAG', 'MTJ', 'EAU', 'YAK', 'ABI', 'SMX', 'KOA', 'MSY', 'DFW', 'SJU', 'CLD', 'BNA', 'HOU', 'PHF', 'DIK', 'BQK', 'BIS', 'MIB', 'LNK', 'CSG', 'IPL', 'MRY', 'MWH', 'PLN', 'CRW', 'OMA', 'MAZ', 'MOT', 'TTN', 'SBP', 'MSP', 'PIT', 'TEX', 'HTS', 'MGM', 'LIT', 'AEX', 'PIA', 'APN', 'OGG', 'EVV', 'MLI', 'FSM', 'LAR', 'EFD', 'ATL', 'MCO', 'ECP', 'PBG', 'CDV', 'TWF', 'XNA', 'SAT', 'BWI', 'BET', 'DAY', 'CMX', 'OTZ', 'GCC', 'SGU', 'SAV', 'VIS', 'PAH', 'CMH', 'LAS', 'TUS', 'SNA', 'OME', 'JAX', 'PIE', 'RSW', 'ILM', 'DVL', 'MFR', 'PUB', 'SJT', 'MKG', 'JFK', 'STL', 'CIC', 'CAK', 'SAN', 'CLE', 'STC', 'EGE', 'PHL', 'ORH', 'ILG', 'HDN', 'CLL', 'AZA', 'GFK', 'BHM', 'DSM', 'LNY', 'DAB', 'MYR', 'DTW', 'SFO', 'MFE', 'TPA', 'ACT', 'SDF', 'CEC', 'DLG', 'TVC', 'RNO', 'AZO', 'PNS', 'PWM', 'LGB', 'MMH', 'MEI', 'HRL', 'BGM', 'LWB', 'BTM', 'BOI', 'FAY', 'KSM', 'ABQ', 'PSP', 'PHX', 'ORF', 'BGR', 'TXK', 'RKS', 'RDM', 'MOB', 'ELM', 'HLN', 'BIL', 'ABY', 'LEX', 'ROW', 'UST', 'BFL', 'UTM', 'CPR', 'BOS', 'CHO', 'IDA', 'GEG', 'COD', 'SPS', 'AVL', 'SIT', 'PSC', 'ART', 'LAN', 'GTF', 'BRD', 'COU', 'FAT', 'SRQ', 'GRK', 'ATW', 'EWR', 'ACK', 'BPT', 'MSN', 'DHN', 'LMT', 'ALO', 'SUX', 'EKO', 'MDT', 'CNY', 'SHV', 'HOB', 'LAX', 'GUM', 'GRR', 'CRP', 'LRD', 'LBB', 'EUG', 'TRI', 'CMI', 'DLH', 'OXR', 'DRT', 'AKN', 'GSO', 'VLD', 'GSP', 'PIB', 'TYS', 'COS', 'MEM', 'AVP', 'BLI', 'MBS', 'LCH', 'ACY', 'BZN', 'YUM', 'SEA', 'PSE', 'IMT', 'ERI', 'ROA', 'RST', 'RAP', 'ACV', 'HSV', 'PVD', 'CID', 'SLC', 'DCA', 'FLL', 'OAJ', 'SPI', 'BMI', 'HNL', 'JAN', 'ANI', 'LBE', 'MKE', 'BQN', 'FSD'}, {'DET'}, {'ICT'}, {'MHK'}, {'ROR'}, {'ROP'}, {'SHD'}, {'GCK'}, {'ISO'}, {'LAW'}, {'OKC'}, {'HYS'}, {'RFD'}, {'FOE'}, {'TUL'}, {'UCA'}, {'HYA'}, {'SPN'}]\n",
      "Converted Weakly Connected Components (WCC): [{'GNV', 'DRO', 'ADK', 'SHD', 'ELP', 'FLG', 'AMA', 'SPN', 'TLH', 'FAR', 'JMS', 'ABE', 'LIH', 'SCC', 'LSE', 'PPG', 'BRO', 'SCE', 'DEN', 'RHI', 'GJT', 'RDU', 'IYK', 'APF', 'FWA', 'OAK', 'ORD', 'SBA', 'TYR', 'SGF', 'JAC', 'AUS', 'ISN', 'ANC', 'BJI', 'LFT', 'LWS', 'MOD', 'CIU', 'MCN', 'AGS', 'ISP', 'MKK', 'GST', 'GRB', 'FLO', 'SUN', 'ONT', 'PSG', 'ITH', 'CDC', 'MSO', 'BKG', 'GPT', 'SYR', 'BUR', 'CHA', 'ITO', 'GTR', 'JLN', 'MIA', 'INL', 'EWN', 'MVY', 'BTV', 'VCT', 'FCA', 'LGA', 'BRW', 'CYS', 'DAL', 'BUF', 'FNT', 'SWF', 'EYW', 'RIC', 'MHT', 'HPN', 'OTH', 'BDL', 'WYS', 'ADQ', 'SAF', 'CVG', 'SMF', 'GUC', 'MCI', 'DUT', 'ROC', 'VPS', 'CLT', 'ASE', 'JNU', 'ESC', 'GGG', 'STX', 'MLB', 'GRI', 'PDX', 'PFN', 'IND', 'WRG', 'MDW', 'PBI', 'STT', 'HVN', 'CHS', 'IAD', 'ALB', 'LYH', 'CAE', 'TOL', 'VEL', 'MQT', 'BTR', 'HIB', 'IAH', 'KTN', 'ILE', 'MLU', 'SBN', 'SJC', 'PIH', 'FAI', 'RDD', 'MAF', 'CWA', 'ABR', 'DBQ', 'IAG', 'MTJ', 'EAU', 'YAK', 'ABI', 'SMX', 'KOA', 'MSY', 'DFW', 'SJU', 'CLD', 'BNA', 'HOU', 'PHF', 'DIK', 'BQK', 'BIS', 'MIB', 'LNK', 'CSG', 'IPL', 'MRY', 'MWH', 'PLN', 'CRW', 'OMA', 'MAZ', 'MOT', 'TTN', 'SBP', 'MSP', 'PIT', 'TEX', 'HTS', 'MGM', 'LIT', 'AEX', 'PIA', 'APN', 'OGG', 'EVV', 'MLI', 'FSM', 'LAR', 'EFD', 'ATL', 'MCO', 'ECP', 'PBG', 'CDV', 'TWF', 'XNA', 'SAT', 'BWI', 'BET', 'DAY', 'CMX', 'OTZ', 'GCC', 'SGU', 'SAV', 'VIS', 'PAH', 'CMH', 'LAS', 'TUS', 'SNA', 'OME', 'JAX', 'PIE', 'RSW', 'ILM', 'DVL', 'MFR', 'PUB', 'SJT', 'MKG', 'JFK', 'STL', 'CIC', 'CAK', 'SAN', 'CLE', 'STC', 'EGE', 'PHL', 'ORH', 'ILG', 'HDN', 'CLL', 'AZA', 'GFK', 'BHM', 'DSM', 'LNY', 'DAB', 'MYR', 'DTW', 'SFO', 'MFE', 'TPA', 'ACT', 'SDF', 'CEC', 'DLG', 'TVC', 'RNO', 'AZO', 'PNS', 'PWM', 'LGB', 'MMH', 'MEI', 'HRL', 'BGM', 'LWB', 'BTM', 'BOI', 'FAY', 'KSM', 'ABQ', 'PSP', 'PHX', 'ORF', 'BGR', 'TXK', 'RKS', 'RDM', 'MOB', 'ELM', 'HLN', 'BIL', 'RFD', 'ABY', 'LEX', 'ROW', 'UST', 'BFL', 'UTM', 'CPR', 'BOS', 'CHO', 'IDA', 'GEG', 'COD', 'SPS', 'AVL', 'SIT', 'PSC', 'ART', 'LAN', 'GTF', 'BRD', 'COU', 'FAT', 'SRQ', 'GRK', 'ATW', 'EWR', 'ACK', 'BPT', 'MSN', 'DHN', 'LMT', 'ALO', 'SUX', 'EKO', 'MDT', 'CNY', 'SHV', 'HOB', 'LAX', 'GUM', 'GRR', 'CRP', 'LRD', 'LBB', 'EUG', 'TRI', 'CMI', 'DLH', 'OXR', 'DRT', 'AKN', 'GSO', 'VLD', 'GSP', 'PIB', 'TYS', 'COS', 'MEM', 'AVP', 'BLI', 'MBS', 'LCH', 'ACY', 'BZN', 'YUM', 'SEA', 'PSE', 'IMT', 'ERI', 'ROA', 'RST', 'RAP', 'ACV', 'HSV', 'PVD', 'CID', 'SLC', 'DCA', 'FLL', 'OAJ', 'SPI', 'BMI', 'HNL', 'JAN', 'ANI', 'LBE', 'HYA', 'MKE', 'BQN', 'FSD'}, {'UCA'}, {'TUL'}, {'FOE'}, {'HYS'}, {'OKC'}, {'LAW'}, {'ISO'}, {'GCK'}, {'ROP'}, {'ROR'}, {'MHK'}, {'ICT'}, {'DET'}]\n",
      "The number of strongly connected components is:  18\n",
      "The number of weakly connected components is:  14\n",
      "This graph is NOT strong.\n",
      "This graph is NOT weak.\n",
      "This graph is NOT semiconnected.\n",
      "This graph does NOT consists of a single attracting component.\n",
      "These are the 15 attracting component(s): [{'SHD'}, {'RFD'}, {'UCA'}, {'TUL'}, {'FOE'}, {'HYS'}, {'OKC'}, {'LAW'}, {'ISO'}, {'GCK'}, {'ROP'}, {'ROR'}, {'MHK'}, {'ICT'}, {'DET'}]\n"
     ]
    }
   ],
   "source": [
    "# Strong connectivity\n",
    "isc = nx.is_strongly_connected(flightGraph)\n",
    "ns_conn_comps = nx.number_strongly_connected_components(flightGraph)\n",
    "s_conn_comps = nx.strongly_connected_components(flightGraph)\n",
    "ks_conn_comp = nx.kosaraju_strongly_connected_components(flightGraph)\n",
    "\n",
    "# Weak connectivity\n",
    "iwc = nx.is_weakly_connected(flightGraph)\n",
    "nwcc = nx.number_weakly_connected_components(flightGraph)\n",
    "wcc = nx.weakly_connected_components(flightGraph)\n",
    "\n",
    "# Attracting components\n",
    "iac = nx.is_attracting_component(flightGraph)\n",
    "nac = nx.number_attracting_components(flightGraph)\n",
    "attr_comps = nx.attracting_components(flightGraph)\n",
    "\n",
    "# Semiconnectedness\n",
    "is_semiconnected = nx.is_semiconnected(flightGraph)\n",
    "\n",
    "# Unpack generator results\n",
    "list_of_scc = [\n",
    "    c\n",
    "    for c in sorted(\n",
    "        s_conn_comps, \n",
    "        key=len, \n",
    "        reverse=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "list_of_ks_conn_comp = [\n",
    "    c\n",
    "    for c in sorted(\n",
    "        ks_conn_comp, \n",
    "        key=len, \n",
    "        reverse=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "list_of_wcc = [\n",
    "    c\n",
    "    for c in sorted(\n",
    "        wcc, \n",
    "        key=len, \n",
    "        reverse=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "list_of_attr_comps = [c for c in attr_comps]\n",
    "\n",
    "# Convert node ids to airport_code attribute values\n",
    "scc = convert_node_ids_to_airport_codes(\n",
    "    list_of_scc, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "ks_conn_comp = convert_node_ids_to_airport_codes(\n",
    "    list_of_ks_conn_comp, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "wcc = convert_node_ids_to_airport_codes(\n",
    "    list_of_wcc, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "attr_comps = convert_node_ids_to_airport_codes(\n",
    "    list_of_attr_comps, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "\n",
    "# Boolean outputs\n",
    "def connected_strength_output(isc, iwc, is_semiconnected):\n",
    "    isc_output = \"is NOT strong\" if isc == False else \"strong\"\n",
    "    iwc_output = \"is NOT weak\" if iwc == False else \"weak\"\n",
    "    is_semiconnected_output = \"is NOT semiconnected\" if is_semiconnected == False else \"is semiconnected\"\n",
    "    \n",
    "    print(f\"This graph {isc_output}.\")\n",
    "    print(f\"This graph {iwc_output}.\")\n",
    "    print(f\"This graph {is_semiconnected_output}.\")\n",
    "\n",
    "# Print Results\n",
    "print(\"Converted Strongly Connected Components (SCC):\", scc)\n",
    "print(\"Converted Kosaraju SCC:\", ks_conn_comp)\n",
    "print(\"Converted Weakly Connected Components (WCC):\", wcc)\n",
    "print(\"The number of strongly connected components is: \", ns_conn_comps)\n",
    "print(\"The number of weakly connected components is: \", nwcc)\n",
    "\n",
    "connected_strength_output(\n",
    "    isc=isc, \n",
    "    iwc=iwc, \n",
    "    is_semiconnected=is_semiconnected\n",
    "    )\n",
    "\n",
    "iac_output = \"NOT \" if not iac else \"\"\n",
    "list_of_attr_comps = convert_node_ids_to_airport_codes(list_of_attr_comps, id_to_airport_code_mapping_dict)\n",
    "\n",
    "print(f\"This graph does {iac_output}consists of a single attracting component.\")\n",
    "print(f\"These are the {nac} attracting component(s): {list_of_attr_comps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Measures\n",
    "- harmonic_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Harmonic Diameter is 2.391734958945008\n"
     ]
    }
   ],
   "source": [
    "harmonic_diameter = nx.harmonic_diameter(flightGraph)\n",
    "\n",
    "print(\"The Harmonic Diameter is\", harmonic_diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dominating Sets\n",
    "- dominating_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dominating Set includes these 212 airports: \n",
      "['ABR', 'EWR', 'RST', 'LWB', 'MOB', 'FNT', 'BGM', 'TEX', 'MOT', 'MHK', 'CRW', 'HTS', 'GEG', 'BRW', 'LGB', 'HRL', 'ELP', 'UTM', 'MEI', 'IDA', 'ITH', 'BFL', 'AMA', 'VIS', 'VPS', 'SHD', 'DLH', 'CDC', 'GUM', 'ROW', 'COU', 'MCN', 'HLN', 'FOE', 'RFD', 'CMI', 'FAR', 'CHA', 'GRB', 'ECP', 'RAP', 'MAZ', 'VEL', 'MGM', 'OXR', 'ORH', 'TRI', 'FSD', 'GGG', 'TUL', 'HYS', 'ABY', 'OTH', 'IAG', 'SPI', 'CYS', 'UCA', 'JNU', 'DVL', 'ANI', 'MKG', 'MSO', 'LNY', 'LBE', 'RHI', 'DHN', 'WYS', 'CLD', 'GRI', 'ISN', 'ISO', 'CEC', 'ATW', 'PHF', 'CLL', 'TVC', 'UST', 'PFN', 'ROR', 'AZO', 'IYK', 'SJT', 'GJT', 'FAY', 'JLN', 'ART', 'LMT', 'BPT', 'EVV', 'AKN', 'BRO', 'VLD', 'GCK', 'STC', 'CMX', 'BKG', 'ICT', 'EUG', 'BMI', 'SBA', 'PAH', 'CNY', 'DIK', 'MWH', 'BIS', 'ABE', 'AEX', 'CWA', 'CIC', 'SUN', 'MMH', 'PUB', 'LWS', 'PLN', 'ESC', 'COD', 'EWN', 'ERI', 'GPT', 'CDV', 'MBS', 'CPR', 'GCC', 'ISP', 'ILM', 'LAR', 'ACY', 'LSE', 'IPL', 'BLI', 'GUC', 'SGF', 'ASE', 'HVN', 'MFR', 'CID', 'BQK', 'PIH', 'SPS', 'PIE', 'ABI', 'DRO', 'RDD', 'LAW', 'TXK', 'ADQ', 'PSE', 'GNV', 'VCT', 'CIU', 'HOB', 'MOD', 'STX', 'TOL', 'KOA', 'LNK', 'CRP', 'HYA', 'HIB', 'BET', 'RDM', 'DET', 'FLO', 'MIB', 'ILG', 'OKC', 'EFD', 'OAJ', 'APF', 'SMX', 'LYH', 'SUX', 'ILE', 'ACT', 'MFE', 'BTM', 'AZA', 'GRK', 'OTZ', 'LIH', 'ROP', 'LCH', 'MRY', 'FLG', 'BJI', 'RNO', 'TYR', 'DRT', 'WRG', 'GFK', 'SWF', 'ALO', 'SAF', 'PIA', 'BUR', 'MVY', 'TWF', 'SCE', 'PSP', 'DUT', 'TLH', 'EYW', 'SBP', 'FSM', 'BRD', 'DBQ', 'CHO', 'SPN', 'PPG', 'LRD', 'CSG', 'PBG']\n"
     ]
    }
   ],
   "source": [
    "dominating_set = list(nx.dominating_set(\n",
    "    flightGraph, \n",
    "    start_with=None\n",
    "    ))\n",
    "\n",
    "# Applying the conversion function\n",
    "dominating_set_airport_codes = convert_list(\n",
    "    dominating_set, \n",
    "    id_to_airport_code_mapping_dict\n",
    "    )\n",
    "\n",
    "# Output the result\n",
    "print(f\"\"\"The Dominating Set includes these {len(dominating_set)} airports: \n",
    "{dominating_set_airport_codes}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular\n",
    "- is_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This graph is NOT regular.\n"
     ]
    }
   ],
   "source": [
    "is_regular = nx.is_regular(flightGraph)\n",
    "\n",
    "if is_regular:\n",
    "    print(\"This graph is regular.\")\n",
    "else:\n",
    "    print(\"This graph is NOT regular.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
